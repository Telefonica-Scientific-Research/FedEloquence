criterion:
  type: CrossEntropyLoss
data:
  root: data/
  splits:
  - 0.48
  - 0.01
  - 0.01
  splitter: iid
  type: alpaca@llm
  domain_type: 'single'
dataloader:
  batch_size: 1
device: 1
early_stop:
  patience: 0
eval:
  count_flops: false
  freq: 10
  metrics:
  - loss
  len_server_dataset: 1000
expname_tag: ds_15c_1000r_30ls
federate:
  client_num: 15
  master_port: 29340
  method: FedAvg
  mode: standalone
  online_aggr: false
  process_num: 1
  adapt_save_to: finetuned_adapters/comparable/occiglot-7B-eu5-instruct/ds_15c_1000r_30ls.ckpt
  share_local_model: true
  total_round_num: 1000
llm:
  adapter:
    args:
    - adapter_method: lora
      adapter_package: peft
      lora_alpha: 16
      lora_dropout: 0.05
      r: 8
      target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj
      - lm_head
    use: true
  chat:
    max_len: 2000
  deepspeed:
    ds_config: federatedscope/llm/deepspeed/ds_config_4bs.json
    use: true
  tok_len: 1000
  prompt_path: prompt_templates/alpaca
model:
  type: occiglot/occiglot-7B-eu5-instruct@huggingface_llm
train:
  batch_or_epoch: batch
  is_enable_half: true
  local_update_steps: 30
  optimizer:
    lr: 0.0003
    weight_decay: 0.0
trainer:
  type: llmtrainer
use_gpu: true
