criterion:
  type: CrossEntropyLoss
data:
  root: data/
  splits:
  - 0.096
  - 0.002
  - 0.002
  splitter: iid
  type: alpaca@llm
dataloader:
  batch_size: 1
device: 3
early_stop:
  patience: 3
  delta: 0
eval:
  count_flops: false
  freq: 5
  metrics:
  - loss
expname_tag: ds_3c_1000r_30ls_earlystop_3pat
federate:
  client_num: 3
  master_port: 29340
  method: FedAvg
  mode: standalone
  online_aggr: false
  process_num: 1
  adapt_save_to: finetuned_adapters/comparable/EuroLLM-1.7B-Instruct/early_stop/ds_3c_1000r_30ls_3pat.ckpt
  share_local_model: true
  total_round_num: 1000
  use_global_early_stop: False
  use_local_early_stop: True
  save_client_model: False # To save best client models
llm:
  adapter:
    args:
    - adapter_method: lora
      adapter_package: peft
      lora_alpha: 16
      lora_dropout: 0.05
      r: 8
      target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj
      - lm_head
    use: true
  chat:
    max_len: 2000
  deepspeed:
    ds_config: federatedscope/llm/deepspeed/ds_config_4bs.json
    use: true
  tok_len: 1000
  prompt_path: prompt_templates/alpaca
  model_save_to: models_with_ft_adapt/comparable/EuroLLM-1.7B-Instruct/early_stop
  to_hf_format: 
    use: true
    hash_code_model_snapshot: ""
model:
  type: utter-project/EuroLLM-1.7B-Instruct@huggingface_llm
train:
  batch_or_epoch: batch
  is_enable_half: true
  local_update_steps: 30
  optimizer:
    lr: 0.0003
    weight_decay: 0.0
trainer:
  type: llmtrainer
use_gpu: true